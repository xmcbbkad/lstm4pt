{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 988,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 989,
   "metadata": {},
   "outputs": [],
   "source": [
    "def str2ts(x):\n",
    "    time_string = x + ' GMT-0500'\n",
    "    dt = datetime.datetime.strptime(time_string, '%Y-%m-%d %H:%M:%S GMT%z')\n",
    "    ts = int(dt.timestamp())\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1005,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv('./ts_2k.csv',usecols=[0,1,2,3,4])\n",
    "ts = dt['date'].apply(str2ts)\n",
    "dt.insert(1, 'ts', ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>ts</th>\n",
       "      <th>open</th>\n",
       "      <th>high</th>\n",
       "      <th>low</th>\n",
       "      <th>close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2022-02-25 15:59:00</td>\n",
       "      <td>1645822740</td>\n",
       "      <td>809.61</td>\n",
       "      <td>809.99</td>\n",
       "      <td>809.20</td>\n",
       "      <td>809.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-02-25 15:58:00</td>\n",
       "      <td>1645822680</td>\n",
       "      <td>808.52</td>\n",
       "      <td>809.94</td>\n",
       "      <td>808.29</td>\n",
       "      <td>809.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-02-25 15:57:00</td>\n",
       "      <td>1645822620</td>\n",
       "      <td>809.30</td>\n",
       "      <td>809.50</td>\n",
       "      <td>807.24</td>\n",
       "      <td>808.49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-02-25 15:56:00</td>\n",
       "      <td>1645822560</td>\n",
       "      <td>810.27</td>\n",
       "      <td>810.51</td>\n",
       "      <td>809.11</td>\n",
       "      <td>809.22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-02-25 15:55:00</td>\n",
       "      <td>1645822500</td>\n",
       "      <td>809.41</td>\n",
       "      <td>810.64</td>\n",
       "      <td>809.00</td>\n",
       "      <td>810.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2022-02-25 15:54:00</td>\n",
       "      <td>1645822440</td>\n",
       "      <td>809.66</td>\n",
       "      <td>810.04</td>\n",
       "      <td>808.81</td>\n",
       "      <td>809.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2022-02-25 15:53:00</td>\n",
       "      <td>1645822380</td>\n",
       "      <td>807.96</td>\n",
       "      <td>809.68</td>\n",
       "      <td>807.91</td>\n",
       "      <td>809.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022-02-25 15:52:00</td>\n",
       "      <td>1645822320</td>\n",
       "      <td>807.41</td>\n",
       "      <td>808.07</td>\n",
       "      <td>806.71</td>\n",
       "      <td>808.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022-02-25 15:51:00</td>\n",
       "      <td>1645822260</td>\n",
       "      <td>806.21</td>\n",
       "      <td>807.67</td>\n",
       "      <td>806.11</td>\n",
       "      <td>807.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022-02-25 15:50:00</td>\n",
       "      <td>1645822200</td>\n",
       "      <td>805.87</td>\n",
       "      <td>806.74</td>\n",
       "      <td>804.51</td>\n",
       "      <td>806.44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  date          ts    open    high     low   close\n",
       "0  2022-02-25 15:59:00  1645822740  809.61  809.99  809.20  809.87\n",
       "1  2022-02-25 15:58:00  1645822680  808.52  809.94  808.29  809.70\n",
       "2  2022-02-25 15:57:00  1645822620  809.30  809.50  807.24  808.49\n",
       "3  2022-02-25 15:56:00  1645822560  810.27  810.51  809.11  809.22\n",
       "4  2022-02-25 15:55:00  1645822500  809.41  810.64  809.00  810.42\n",
       "5  2022-02-25 15:54:00  1645822440  809.66  810.04  808.81  809.38\n",
       "6  2022-02-25 15:53:00  1645822380  807.96  809.68  807.91  809.50\n",
       "7  2022-02-25 15:52:00  1645822320  807.41  808.07  806.71  808.00\n",
       "8  2022-02-25 15:51:00  1645822260  806.21  807.67  806.11  807.42\n",
       "9  2022-02-25 15:50:00  1645822200  805.87  806.74  804.51  806.44"
      ]
     },
     "execution_count": 1006,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dt.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 925,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset(dt, step):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    debug_all = []\n",
    "    for i in range(len(dt)- step):\n",
    "        dt_continue = True\n",
    "        line = '1'\n",
    "        data_x = [[1.0],]\n",
    "        data_y = 0\n",
    "        for j in range(i+step-1, i-1, -1):\n",
    "            #print(j)\n",
    "            if dt.loc[j]['ts']-dt.loc[j+1]['ts'] != 60:\n",
    "                dt_continue = False\n",
    "                break\n",
    "            \n",
    "            value = dt.loc[j]['close']/dt.loc[j+1]['close']\n",
    "            line += \"\\t{}\".format(value)\n",
    "            if j==i:\n",
    "                data_y = value\n",
    "            else:\n",
    "                data_x.append([value])\n",
    "        if not dt_continue:\n",
    "            #print(i)\n",
    "            #return\n",
    "            continue\n",
    "        data_X.append(data_x)\n",
    "        data_Y.append(data_y)\n",
    "        debug_all.append(line)\n",
    "        if(i%1000 == 0):\n",
    "            print(line)\n",
    "            print(\"==========={}\".format(i))\n",
    "    return debug_all, np.array(data_X, dtype=np.float32), np.array(data_Y, dtype=np.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\t1.0012788517649398\t1.0012152174991318\t1.0007183374204256\t1.0018564356435644\t0.9998517603458925\t1.0012849341471248\t0.9985192862959947\t0.9990978967400707\t1.0014966171504904\t1.0002099543040632\n",
      "===========0\n"
     ]
    }
   ],
   "source": [
    "debug_all, data_X, data_Y = create_dataset(dt=dt, step=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataset_all(dt, step):\n",
    "    data_X = []\n",
    "    data_Y = []\n",
    "    data_time_X = []\n",
    "    data_time_Y = []\n",
    "    for i in range(len(dt)-1, step-1, -1):\n",
    "        dt_continue = True\n",
    "        #print(\"i=\",i)\n",
    "        data_x = []\n",
    "        data_y = None\n",
    "        data_time_x = []\n",
    "        data_time_y = None\n",
    "        for j in range(i, i-step-1, -1):\n",
    "            #print(\"-----j=\",j)\n",
    "            if j == i:   #序列中的第一个\n",
    "                a = dt.loc[j]['open']\n",
    "                one = [(dt.loc[j]['high']-a)*10.0/a, (dt.loc[j]['low']-a)*10.0/a, (dt.loc[j]['close']-a)*10.0/a] \n",
    "                #one = [dt.loc[j]['high']/dt.loc[j]['open'], dt.loc[j]['low']/dt.loc[j]['open'], dt.loc[j]['close']/dt.loc[j]['open']] \n",
    "\n",
    "                data_x.append(one)\n",
    "                data_time_x.append([dt.loc[j]['date']])\n",
    "            else:\n",
    "                if dt.loc[j]['ts']-dt.loc[j+1]['ts'] != 60: #判断是否是连续的\n",
    "                    dt_continue = False\n",
    "                    break\n",
    "            \n",
    "                if j == i-step:  #要预测的\n",
    "                    data_y = dt.loc[j]['close']/dt.loc[j+1]['close']\n",
    "                    #data_y = 1 if data_y>1.002 else 0\n",
    "                    data_y = 1 if data_y>1 else 0\n",
    "                    data_time_y = dt.loc[j]['date']         \n",
    "                else:\n",
    "                    a = dt.loc[j+1]['close']\n",
    "                    one = [(dt.loc[j]['high']-a)*10.0/a, (dt.loc[j]['low']-a)*10.0/a, (dt.loc[j]['close']-a)*10.0/a]\n",
    "                    #one = [dt.loc[j]['high']/dt.loc[j+1]['close'], dt.loc[j]['low']/dt.loc[j+1]['close'], dt.loc[j]['close']/dt.loc[j+1]['close']]\n",
    "                    data_x.append(one) #序列中不是第一个\n",
    "                    data_time_x.append([dt.loc[j]['date']])\n",
    "        \n",
    "        if dt_continue:\n",
    "            data_X.append(data_x)\n",
    "            data_Y.append(data_y)\n",
    "            data_time_X.append(data_time_x)\n",
    "            data_time_Y.append(data_time_y)\n",
    "        \n",
    "        if(i%1000 == 0):\n",
    "            print(\"==========={}\".format(i))\n",
    "                \n",
    "            \n",
    "    #return data_time, np.array(data_X, dtype=np.float32), np.array(data_Y, dtype=np.long)\n",
    "    return data_X, data_Y, data_time_X, data_time_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1008,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===========1000\n"
     ]
    }
   ],
   "source": [
    "data_X, data_Y, data_time_X, data_time_Y = create_dataset_all(dt=dt, step=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879\n",
      "910\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([[0.01549892335723179, -0.013132675516433752, 0.009228366579115174],\n",
       "  [0.023167848699764022, -0.003073286052009349, 0.014302600472813669],\n",
       "  [0.011803448967788387, -0.010387035091653727, -0.009560793663909292],\n",
       "  [0.014177693761815283, -0.001063327032136482, 0.0087429111531192],\n",
       "  [0.03198998984819553, -0.004603725476308359, 0.025969733456099882],\n",
       "  [0.0025902465443746153, -0.01836720276920973, 0.0007064308757381664],\n",
       "  [0.030374381916647528, -0.010595714622085911, 0.026253826230280414],\n",
       "  [0.027828986766553605, -0.0041097659781832805, 0.021840470626915603],\n",
       "  [-0.0023433197811344652, -0.05073287326155012, -0.032103481001534984],\n",
       "  [0.00211578019394593, -0.0307963561563327, -0.026212165736115407],\n",
       "  [0.026281054070617288, -0.00011785226040624741, 0.0207419978315183],\n",
       "  [0.018111680858071192, -0.0027049912969847366, -0.0007056499035605381],\n",
       "  [0.013173061090070859, -0.007997929947543737, 0.00917409611629899],\n",
       "  [0.030552291421856906, -0.0038777908343130543, 0.012573443008226205],\n",
       "  [0.05480770359242737, -0.010562512469633844, 0.03943337988662786],\n",
       "  [-0.0004676010895101133, -0.08568789965280535, -0.07703727949686028],\n",
       "  [0.011309551859006676, -0.01555063380613602, 0.0004712313274582209],\n",
       "  [0.006832532277825381, -0.018494958062388676, -0.015078691923475317],\n",
       "  [0.01911278905143941, -0.01226993865030766, 0.008258612553090275],\n",
       "  [0.008251797713073742, -0.011670399622775069, -0.002121890840503949]],\n",
       " 0,\n",
       " [['2022-02-22 10:15:00'],\n",
       "  ['2022-02-22 10:16:00'],\n",
       "  ['2022-02-22 10:17:00'],\n",
       "  ['2022-02-22 10:18:00'],\n",
       "  ['2022-02-22 10:19:00'],\n",
       "  ['2022-02-22 10:20:00'],\n",
       "  ['2022-02-22 10:21:00'],\n",
       "  ['2022-02-22 10:22:00'],\n",
       "  ['2022-02-22 10:23:00'],\n",
       "  ['2022-02-22 10:24:00'],\n",
       "  ['2022-02-22 10:25:00'],\n",
       "  ['2022-02-22 10:26:00'],\n",
       "  ['2022-02-22 10:27:00'],\n",
       "  ['2022-02-22 10:28:00'],\n",
       "  ['2022-02-22 10:29:00'],\n",
       "  ['2022-02-22 10:30:00'],\n",
       "  ['2022-02-22 10:31:00'],\n",
       "  ['2022-02-22 10:32:00'],\n",
       "  ['2022-02-22 10:33:00'],\n",
       "  ['2022-02-22 10:34:00']],\n",
       " '2022-02-22 10:35:00')"
      ]
     },
     "execution_count": 1009,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(data_Y))\n",
    "print(sum(data_Y))\n",
    "i=444\n",
    "data_X[i], data_Y[i], data_time_X[i], data_time_Y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1010,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1879\n",
      "1879\n",
      "(1879, 20, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[ 0.02659033, -0.00127226,  0.02519084],\n",
       "        [ 0.0112947 , -0.01027945, -0.00862966],\n",
       "        [ 0.        , -0.01333672, -0.00558872],\n",
       "        [ 0.01385253, -0.00025417,  0.00965864],\n",
       "        [ 0.00355501, -0.0245042 , -0.01980651],\n",
       "        [-0.0007633 , -0.03383965, -0.03231306],\n",
       "        [ 0.0061262 , -0.00957219, -0.00957219],\n",
       "        [ 0.00613207, -0.00498231, -0.00127751],\n",
       "        [ 0.00677169, -0.01354338,  0.00268312],\n",
       "        [ 0.01098508, -0.00983548, -0.00012773],\n",
       "        [ 0.01315672,  0.00012774,  0.00625902],\n",
       "        [ 0.00523386, -0.00497855,  0.00140421],\n",
       "        [-0.00255275, -0.0140401 , -0.00663714],\n",
       "        [ 0.00178811, -0.00830194, -0.00408711],\n",
       "        [ 0.02184941, -0.01034972,  0.01520514],\n",
       "        [ 0.01160981, -0.01301319, -0.01160981],\n",
       "        [ 0.00242684, -0.02375752, -0.02362979],\n",
       "        [ 0.004097  , -0.0057614 , -0.00089622],\n",
       "        [ 0.01357252, -0.00588996,  0.00166455],\n",
       "        [ 0.00755326, -0.00985764,  0.00204834]], dtype=float32),\n",
       " 1)"
      ]
     },
     "execution_count": 1010,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_X = np.array(data_X, dtype=np.float32)\n",
    "data_Y = np.array(data_Y, dtype=np.long)\n",
    "per = np.random.permutation(data_X.shape[0])    #打乱后的行号\n",
    "#print(per)\n",
    "data_X = data_X[per, :, :]    #获取打乱后的训练数据\n",
    "data_Y = data_Y[per]\n",
    "#print(debug_all[1000])\n",
    "#print(data_X)\n",
    "#print(data_X.shape)\n",
    "print(len(data_Y))\n",
    "print(len(data_X))\n",
    "print(data_X.shape)\n",
    "data_X[444], data_Y[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1011,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(len(data_X) * 0.8)\n",
    "train_X = data_X[:train_size]\n",
    "train_Y = data_Y[:train_size]\n",
    "test_X = data_X[train_size:]\n",
    "test_Y = data_Y[train_size:]\n",
    "\n",
    "#train_Y = train_Y.astype(np.long)\n",
    "#test_Y = test_Y.astype(np.long)\n",
    "\n",
    "train_X = train_X.reshape(-1,20,3)\n",
    "train_Y = train_Y.reshape(-1, )\n",
    "test_X = test_X.reshape(-1,20,3)\n",
    "test_Y = test_Y.reshape(-1, )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1012,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1503, 20, 3)\n",
      "(1503,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.02659033, -0.00127226,  0.02519084],\n",
       "       [ 0.0112947 , -0.01027945, -0.00862966],\n",
       "       [ 0.        , -0.01333672, -0.00558872],\n",
       "       [ 0.01385253, -0.00025417,  0.00965864],\n",
       "       [ 0.00355501, -0.0245042 , -0.01980651],\n",
       "       [-0.0007633 , -0.03383965, -0.03231306],\n",
       "       [ 0.0061262 , -0.00957219, -0.00957219],\n",
       "       [ 0.00613207, -0.00498231, -0.00127751],\n",
       "       [ 0.00677169, -0.01354338,  0.00268312],\n",
       "       [ 0.01098508, -0.00983548, -0.00012773],\n",
       "       [ 0.01315672,  0.00012774,  0.00625902],\n",
       "       [ 0.00523386, -0.00497855,  0.00140421],\n",
       "       [-0.00255275, -0.0140401 , -0.00663714],\n",
       "       [ 0.00178811, -0.00830194, -0.00408711],\n",
       "       [ 0.02184941, -0.01034972,  0.01520514],\n",
       "       [ 0.01160981, -0.01301319, -0.01160981],\n",
       "       [ 0.00242684, -0.02375752, -0.02362979],\n",
       "       [ 0.004097  , -0.0057614 , -0.00089622],\n",
       "       [ 0.01357252, -0.00588996,  0.00166455],\n",
       "       [ 0.00755326, -0.00985764,  0.00204834]], dtype=float32)"
      ]
     },
     "execution_count": 1012,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(train_Y.shape)\n",
    "\n",
    "#train_X\n",
    "train_X[444]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_Y)):\n",
    "    #if test_X[i][1][0] >=1:\n",
    "    if test_Y[i] >=1:\n",
    "        test_Y[i] = 1\n",
    "    else:\n",
    "        test_Y[i] = 0\n",
    "    \n",
    "for i in range(len(train_Y)):\n",
    "    #if train_X[i][1][0] >=1:\n",
    "    if train_Y[i] >=1:\n",
    "        train_Y[i] = 1\n",
    "    else:\n",
    "        train_Y[i] = 0\n",
    "        \n",
    "train_x = torch.from_numpy(train_X)\n",
    "train_y = torch.from_numpy(train_Y)\n",
    "test_x = torch.from_numpy(test_X)\n",
    "test_y = torch.from_numpy(test_Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 999,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7583, array([1, 1, 1, ..., 0, 0, 0]))"
      ]
     },
     "execution_count": 999,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_Y),train_Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainDataSet(Dataset):\n",
    "    def __init__(self,x,y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        return\n",
    "    \n",
    "    def __getitem__(self,index):\n",
    "        return self.x[index], self.y[index]\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "dt_train = TrainDataSet(train_X, train_Y)\n",
    "#dt_test = TrainDataSet(test_X, test_Y)\n",
    "train_loader = DataLoader(dt_train, batch_size = 4096,shuffle = True, drop_last=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1001,
   "metadata": {},
   "outputs": [],
   "source": [
    "class lstm(nn.Module):\n",
    "    def __init__(self,input_size=2,hidden_size=4,output_size=1,num_layer=2):\n",
    "        super(lstm,self).__init__()\n",
    "        self.layer1 = nn.LSTM(input_size,hidden_size,num_layer,batch_first=True)\n",
    "        self.layer2 = nn.Linear(hidden_size,output_size)\n",
    "        #input_size: embedding的维度，比如一个字由128维向量描述，则该值是128\n",
    "        # hidden_size：lstm内部隐含层的维度\n",
    "        # output_size：lstm输出向量的维度，比如一句话经过lstm变成一个64维的向量\n",
    "        # lstm参数中并不定义序列的长度，就是不定义由几个lstm_cell串联\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # x的结构：[batch * seq_length * input_size]\n",
    "        # seq_length：序列长度，比如要用前5个单词预测第6个，那么seq_length=5\n",
    "        x,_ = self.layer1(x)\n",
    "        #print(\"x.shape={}\".format(x.shape))\n",
    "        #b,s,h = x.size()\n",
    "        x = x[:,-1,:]\n",
    "        x = self.layer2(x)\n",
    "        #print(\"before:\",x)\n",
    "        x = F.softmax(x,dim=1)\n",
    "        #print(\"after:\",x)\n",
    "        #print(\"x.shape={}\".format(x.shape))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "model = lstm(3, 8, 2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1003,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 500, Loss: 0.66522\n",
      "ALL:1896, TP:392, FP:403, FN:534, TN:567\n",
      "threshold=0.5  precision=0.4930817610056691  recall=0.4233261339088301\n",
      "ALL:1896, TP:271, FP:255, FN:655, TN:715\n",
      "threshold=0.6  precision=0.5152091254743058  recall=0.29265658747268614\n",
      "ALL:1896, TP:190, FP:166, FN:736, TN:804\n",
      "threshold=0.7  precision=0.5337078651670402  recall=0.20518358531295336\n",
      "ALL:1896, TP:115, FP:97, FN:811, TN:873\n",
      "threshold=0.8  precision=0.5424528301861206  recall=0.1241900647946823\n",
      "ALL:1896, TP:48, FP:38, FN:878, TN:932\n",
      "threshold=0.9  precision=0.5581395348772309  recall=0.051835853131693484\n",
      "------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_23083/3668883694.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     86\u001b[0m     \u001b[0;31m#print(\"var_y:\", var_y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0;31m# 前向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m     \u001b[0;31m#print(var_x.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;31m#print(out.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tiger/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_23083/1372290375.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m# x的结构：[batch * seq_length * input_size]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0;31m# seq_length：序列长度，比如要用前5个单词预测第6个，那么seq_length=5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlayer1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m         \u001b[0;31m#print(\"x.shape={}\".format(x.shape))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0;31m#b,s,h = x.size()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tiger/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tiger/lib/python3.7/site-packages/torch/nn/modules/rnn.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, hx)\u001b[0m\n\u001b[1;32m    690\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mbatch_sizes\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    691\u001b[0m             result = _VF.lstm(input, hx, self._flat_weights, self.bias, self.num_layers,\n\u001b[0;32m--> 692\u001b[0;31m                               self.dropout, self.training, self.bidirectional, self.batch_first)\n\u001b[0m\u001b[1;32m    693\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    694\u001b[0m             result = _VF.lstm(input, batch_sizes, hx, self._flat_weights, self.bias,\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "#optimizer = torch.optim.SGD(model.parameters(), lr=0.01)\n",
    "\n",
    "def cal_acc(pred_y, true_y, threshold=0.5):\n",
    "    #print(\"pred_y:\",pred_y)\n",
    "    #pre = torch.where(pred_y>threshold, 1, 0)\n",
    "    pre = pred_y.clone()\n",
    "    for i in range(len(pre)):\n",
    "        if pre[i][1] >= threshold:\n",
    "            pre[i][1] = 1\n",
    "            pre[i][0] = 0\n",
    "        else:\n",
    "            pre[i][0] = 1\n",
    "            pre[i][1] = 0\n",
    "        \n",
    "    #print(\"pre:\", pre)\n",
    "    #acc_all = sum(pre.indices == true_y)/len(true_y)\n",
    "    TP = 0  # 1-->1\n",
    "    FP = 0  # 0-->1\n",
    "    FN = 0  # 1-->0\n",
    "    TN = 0  # 1-->1\n",
    "    ALL = 0\n",
    "    for i in range(len(true_y)):\n",
    "        #print(true_y[i], pre[i])\n",
    "        if true_y[i] == 1 and pre[i][1] == 1:\n",
    "            TP +=1\n",
    "        elif true_y[i] == 0 and pre[i][1] == 1:\n",
    "            FP += 1\n",
    "        elif true_y[i] == 1 and pre[i][0] == 1:\n",
    "            FN += 1\n",
    "        elif true_y[i] == 0 and pre[i][0] == 1:\n",
    "            TN += 1\n",
    "        ALL += 1\n",
    "    \n",
    "    print(\"ALL:{}, TP:{}, FP:{}, FN:{}, TN:{}\".format(ALL, TP, FP, FN, TN))\n",
    "    \n",
    "    precision = TP*1.0/(TP+FP+0.000000001)\n",
    "    recall = TP*1.0/(TP+FN+0.000000001)\n",
    "    print(\"threshold={}  precision={}  recall={}\".format(threshold, precision, recall))\n",
    "\n",
    "def eval(model, data_x, data_y):\n",
    "    model = model.eval()\n",
    "    var_data = Variable(data_x)\n",
    "    #print(var_data.shape)\n",
    "    pred_test = model(var_data) # 测试集的预测结果\n",
    "    #print(\"pred_test.shape:{}\".format(pred_test.shape))\n",
    "    #print(\"data_y\".shape)\n",
    "    prediction = torch.max(pred_test, 1)\n",
    "    #print(pred_test)\n",
    "    #print(prediction.indices.shape)\n",
    "    #print(data_y.shape)\n",
    "    #print(pred_test)\n",
    "    #accuracy = sum(prediction.indices == data_y)/len(data_y)\n",
    "    #print(\"acc:{}\".format(accuracy))\n",
    "    \n",
    "    cal_acc(pred_test, data_y, 0.5)\n",
    "    cal_acc(pred_test, data_y, 0.6)\n",
    "    cal_acc(pred_test, data_y, 0.7)\n",
    "    cal_acc(pred_test, data_y, 0.8)\n",
    "    cal_acc(pred_test, data_y, 0.9)\n",
    "    print(\"------------------------\")\n",
    "\n",
    "\n",
    "    \n",
    "for epoch in range(0):\n",
    "    for i,data in enumerate(train_loader):\n",
    "        var_x, var_y = data\n",
    "        out = model(var_x)\n",
    "        loss = criterion(out, var_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if (epoch + 1) % 100 == 0: # 每 100 次输出结果\n",
    "        print('Epoch: {}, Loss: {:.5f}'.format(epoch + 1, loss.data))\n",
    "        eval(model, test_x, test_y)\n",
    "        \n",
    "    \n",
    "for e in range(500000):\n",
    "    var_x = Variable(train_x)\n",
    "    var_y = Variable(train_y)\n",
    "    #print(\"var_x.shape:\", var_x.shape)\n",
    "    #print(\"var_y.shape:\", var_y.shape)\n",
    "    #print(\"var_x:\", var_x)\n",
    "    #print(\"var_y:\", var_y)\n",
    "    # 前向传播\n",
    "    out = model(var_x)\n",
    "    #print(var_x.shape)\n",
    "    #print(out.shape)\n",
    "    #print(out.dtype)\n",
    "    #print(var_y.shape)\n",
    "    #print(var_y.dtype)\n",
    "    #print(out)\n",
    "    #print(var_y)\n",
    "    loss = criterion(out, var_y)\n",
    "    # 反向传播\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    #print(e)\n",
    "    #print(loss.data)\n",
    "    \n",
    "    if (e + 1) % 500 == 0: # 每 100 次输出结果\n",
    "        print('Epoch: {}, Loss: {:.5f}'.format(e + 1, loss.data))\n",
    "        eval(model, test_x, test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tiger",
   "language": "python",
   "name": "tiger"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
